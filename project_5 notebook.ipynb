{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Task: Describe the goals of your study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Aquire the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the remote database, 2. Query the database and aggregate the data, 5. What are the risks and assumptions of our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!NOTE!! I experiened package configuration issues when approaching the SQL portion of this project and simply the read data in from the attached .csv file.  Patrick told me to just note this (done here!) and move on rather than retroactively inputing this from the remote DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Reading in of the Data from the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_raw = pd.DataFrame(pd.read_csv('train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 PassengerId    397386.0000\n",
      "Survived          342.0000\n",
      "Pclass           2057.0000\n",
      "Age             21205.1700\n",
      "SibSp             466.0000\n",
      "Parch             340.0000\n",
      "Fare            28693.9493\n",
      "dtype: float64    PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S   PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object        PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print len(data_raw), \n",
    "print data_raw.sum(), \n",
    "print data_raw.head(), \n",
    "print data_raw.dtypes, \n",
    "print data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data describes many characteristics of passengers on the Titanic (including their paid Fare, Class, Age, port of origin, their numer of siblings(if applicable), their number of children(if applicable), and a binary value indicating whether or not they survived the disaster itself.  The age column contails 177 null values, and the cabin contails 687 total null values... I plan on solving this by not using the Cabin value in my models, and dropping all passengers whose age is a null value as this will still give me enough information to model with w/o having to make intuitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histrogram of age, dropped NA age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  54.,   46.,  177.,  169.,  118.,   70.,   45.,   24.,    9.,    2.]),\n",
       " array([  0.42 ,   8.378,  16.336,  24.294,  32.252,  40.21 ,  48.168,\n",
       "         56.126,  64.084,  72.042,  80.   ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAECCAYAAADw0Rw8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11773c750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_hist = data_raw['Age'].sort_values()\n",
    "age_hist.dropna(inplace=True)\n",
    "plt.hist(age_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "plotting distribution of fare values with high value outliers removed (the outliers made it extremely difficult to view the patterns in the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117928610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAERCAYAAACXT3dwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlYihL0klYuhLUokY+pJUIoa+JJXI/wfbo1LvEOXGuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d04950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fare_hist = data_raw['Fare'].sort_values()\n",
    "fare_hist = fare_hist.where(fare_hist < 300).sort_values()\n",
    "fare_hist.dropna(inplace=True)\n",
    "sns.distplot(fare_hist, kde= False, bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Dummy Variables for *Sex* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(data_raw['Sex'])\n",
    "data_raw= data_raw.drop(['Sex'], axis=1)\n",
    "data_raw = pd.concat([data_raw, sex_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "creating dummy variables for class & cleanning the non-predictive/null value columns from the data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_raw = data_raw.drop(['Cabin', 'Ticket', 'Name'], axis=1)\n",
    "class_dummies = pd.get_dummies(data_raw['Pclass'])\n",
    "data_raw = data_raw.drop(['Pclass'], axis=1)\n",
    "data_raw = pd.concat([data_raw, class_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping null values from the data frame as per above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Logistic Regression and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the variables that we will use in our classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = ['Age', 'SibSp', 'Parch', 'Fare', 'female', 'male', 1, 2, 3]\n",
    "X = data_raw[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform \"Y\" into a 1-Dimensional Array for SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data_raw['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conduct the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Examine the coefficients to see our correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Age', u'SibSp', u'Parch', u'Fare', u'female', u'male', 1, 2, 3], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0393573 , -0.3695578 , -0.08118767,  0.00282379,  1.60056346,\n",
       "        -0.87456487,  1.47046273,  0.10575287, -0.85021701]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X.columns\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test the Model by introducing a *Test* or *Validaton* set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146067415730337"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Predict the class labels for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Predict the class probabilities for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94257832,  0.05742168],\n",
       "       [ 0.89954901,  0.10045099],\n",
       "       [ 0.09231614,  0.90768386],\n",
       "       [ 0.11544819,  0.88455181],\n",
       "       [ 0.43026048,  0.56973952],\n",
       "       [ 0.55999778,  0.44000222],\n",
       "       [ 0.85850257,  0.14149743],\n",
       "       [ 0.24530406,  0.75469594],\n",
       "       [ 0.89591861,  0.10408139],\n",
       "       [ 0.36429739,  0.63570261],\n",
       "       [ 0.80585836,  0.19414164],\n",
       "       [ 0.69068802,  0.30931198],\n",
       "       [ 0.44961607,  0.55038393],\n",
       "       [ 0.93829122,  0.06170878],\n",
       "       [ 0.68156047,  0.31843953],\n",
       "       [ 0.17311296,  0.82688704],\n",
       "       [ 0.26129611,  0.73870389],\n",
       "       [ 0.90095202,  0.09904798],\n",
       "       [ 0.86780686,  0.13219314],\n",
       "       [ 0.56017407,  0.43982593],\n",
       "       [ 0.21168719,  0.78831281],\n",
       "       [ 0.4882027 ,  0.5117973 ],\n",
       "       [ 0.9134401 ,  0.0865599 ],\n",
       "       [ 0.05679037,  0.94320963],\n",
       "       [ 0.80069905,  0.19930095],\n",
       "       [ 0.05857638,  0.94142362],\n",
       "       [ 0.10091642,  0.89908358],\n",
       "       [ 0.61615965,  0.38384035],\n",
       "       [ 0.72403588,  0.27596412],\n",
       "       [ 0.50511325,  0.49488675],\n",
       "       [ 0.43407399,  0.56592601],\n",
       "       [ 0.88309425,  0.11690575],\n",
       "       [ 0.75925934,  0.24074066],\n",
       "       [ 0.28727447,  0.71272553],\n",
       "       [ 0.56486777,  0.43513223],\n",
       "       [ 0.8951587 ,  0.1048413 ],\n",
       "       [ 0.84858357,  0.15141643],\n",
       "       [ 0.56276605,  0.43723395],\n",
       "       [ 0.31236621,  0.68763379],\n",
       "       [ 0.91025786,  0.08974214],\n",
       "       [ 0.92080363,  0.07919637],\n",
       "       [ 0.8236157 ,  0.1763843 ],\n",
       "       [ 0.87220834,  0.12779166],\n",
       "       [ 0.08449241,  0.91550759],\n",
       "       [ 0.94361552,  0.05638448],\n",
       "       [ 0.25881029,  0.74118971],\n",
       "       [ 0.70987963,  0.29012037],\n",
       "       [ 0.86344964,  0.13655036],\n",
       "       [ 0.97167079,  0.02832921],\n",
       "       [ 0.85850257,  0.14149743],\n",
       "       [ 0.05509041,  0.94490959],\n",
       "       [ 0.50023971,  0.49976029],\n",
       "       [ 0.75177633,  0.24822367],\n",
       "       [ 0.78118704,  0.21881296],\n",
       "       [ 0.85856831,  0.14143169],\n",
       "       [ 0.14220124,  0.85779876],\n",
       "       [ 0.89650957,  0.10349043],\n",
       "       [ 0.86221549,  0.13778451],\n",
       "       [ 0.0500242 ,  0.9499758 ],\n",
       "       [ 0.03359814,  0.96640186],\n",
       "       [ 0.67792362,  0.32207638],\n",
       "       [ 0.63502396,  0.36497604],\n",
       "       [ 0.85845968,  0.14154032],\n",
       "       [ 0.10493256,  0.89506744],\n",
       "       [ 0.70619197,  0.29380803],\n",
       "       [ 0.89266539,  0.10733461],\n",
       "       [ 0.10453354,  0.89546646],\n",
       "       [ 0.91281314,  0.08718686],\n",
       "       [ 0.94217761,  0.05782239],\n",
       "       [ 0.91201034,  0.08798966],\n",
       "       [ 0.11401379,  0.88598621],\n",
       "       [ 0.08178967,  0.91821033],\n",
       "       [ 0.91875786,  0.08124214],\n",
       "       [ 0.75813829,  0.24186171],\n",
       "       [ 0.90343941,  0.09656059],\n",
       "       [ 0.49009263,  0.50990737],\n",
       "       [ 0.91004627,  0.08995373],\n",
       "       [ 0.88080949,  0.11919051],\n",
       "       [ 0.86317473,  0.13682527],\n",
       "       [ 0.46375538,  0.53624462],\n",
       "       [ 0.592476  ,  0.407524  ],\n",
       "       [ 0.73816512,  0.26183488],\n",
       "       [ 0.76033652,  0.23966348],\n",
       "       [ 0.83236389,  0.16763611],\n",
       "       [ 0.57177527,  0.42822473],\n",
       "       [ 0.47941986,  0.52058014],\n",
       "       [ 0.87238267,  0.12761733],\n",
       "       [ 0.89407976,  0.10592024],\n",
       "       [ 0.87683653,  0.12316347],\n",
       "       [ 0.22561444,  0.77438556],\n",
       "       [ 0.3734592 ,  0.6265408 ],\n",
       "       [ 0.14704794,  0.85295206],\n",
       "       [ 0.94391472,  0.05608528],\n",
       "       [ 0.54737381,  0.45262619],\n",
       "       [ 0.84626824,  0.15373176],\n",
       "       [ 0.89098911,  0.10901089],\n",
       "       [ 0.04453583,  0.95546417],\n",
       "       [ 0.89629979,  0.10370021],\n",
       "       [ 0.27187826,  0.72812174],\n",
       "       [ 0.63139645,  0.36860355],\n",
       "       [ 0.51561016,  0.48438984],\n",
       "       [ 0.892191  ,  0.107809  ],\n",
       "       [ 0.07966421,  0.92033579],\n",
       "       [ 0.90476311,  0.09523689],\n",
       "       [ 0.6692164 ,  0.3307836 ],\n",
       "       [ 0.92439361,  0.07560639],\n",
       "       [ 0.88879504,  0.11120496],\n",
       "       [ 0.72121854,  0.27878146],\n",
       "       [ 0.445335  ,  0.554665  ],\n",
       "       [ 0.54341985,  0.45658015],\n",
       "       [ 0.49515953,  0.50484047],\n",
       "       [ 0.87252275,  0.12747725],\n",
       "       [ 0.884646  ,  0.115354  ],\n",
       "       [ 0.02360866,  0.97639134],\n",
       "       [ 0.93516213,  0.06483787],\n",
       "       [ 0.85756032,  0.14243968],\n",
       "       [ 0.60591265,  0.39408735],\n",
       "       [ 0.33272464,  0.66727536],\n",
       "       [ 0.16308358,  0.83691642],\n",
       "       [ 0.67233638,  0.32766362],\n",
       "       [ 0.2699623 ,  0.7300377 ],\n",
       "       [ 0.86344824,  0.13655176],\n",
       "       [ 0.84340406,  0.15659594],\n",
       "       [ 0.93748376,  0.06251624],\n",
       "       [ 0.32064581,  0.67935419],\n",
       "       [ 0.66493216,  0.33506784],\n",
       "       [ 0.83746836,  0.16253164],\n",
       "       [ 0.24243922,  0.75756078],\n",
       "       [ 0.40584302,  0.59415698],\n",
       "       [ 0.60631038,  0.39368962],\n",
       "       [ 0.79128402,  0.20871598],\n",
       "       [ 0.64409715,  0.35590285],\n",
       "       [ 0.04172838,  0.95827162],\n",
       "       [ 0.85367879,  0.14632121],\n",
       "       [ 0.92586548,  0.07413452],\n",
       "       [ 0.37416234,  0.62583766],\n",
       "       [ 0.87965166,  0.12034834],\n",
       "       [ 0.96475132,  0.03524868],\n",
       "       [ 0.87665345,  0.12334655],\n",
       "       [ 0.87683653,  0.12316347],\n",
       "       [ 0.93915939,  0.06084061],\n",
       "       [ 0.45145899,  0.54854101],\n",
       "       [ 0.30173796,  0.69826204],\n",
       "       [ 0.94098517,  0.05901483],\n",
       "       [ 0.85567597,  0.14432403],\n",
       "       [ 0.38968911,  0.61031089],\n",
       "       [ 0.86348293,  0.13651707],\n",
       "       [ 0.84349727,  0.15650273],\n",
       "       [ 0.35964116,  0.64035884],\n",
       "       [ 0.26026973,  0.73973027],\n",
       "       [ 0.40908796,  0.59091204],\n",
       "       [ 0.79318838,  0.20681162],\n",
       "       [ 0.46292111,  0.53707889],\n",
       "       [ 0.91342335,  0.08657665],\n",
       "       [ 0.20652728,  0.79347272],\n",
       "       [ 0.23190268,  0.76809732],\n",
       "       [ 0.59442416,  0.40557584],\n",
       "       [ 0.75309134,  0.24690866],\n",
       "       [ 0.90680879,  0.09319121],\n",
       "       [ 0.90904339,  0.09095661],\n",
       "       [ 0.68608256,  0.31391744],\n",
       "       [ 0.32405591,  0.67594409],\n",
       "       [ 0.68156047,  0.31843953],\n",
       "       [ 0.3640087 ,  0.6359913 ],\n",
       "       [ 0.73256685,  0.26743315],\n",
       "       [ 0.71327063,  0.28672937],\n",
       "       [ 0.11617046,  0.88382954],\n",
       "       [ 0.31162317,  0.68837683],\n",
       "       [ 0.33627225,  0.66372775],\n",
       "       [ 0.92342416,  0.07657584],\n",
       "       [ 0.91801265,  0.08198735],\n",
       "       [ 0.91107023,  0.08892977],\n",
       "       [ 0.90147565,  0.09852435],\n",
       "       [ 0.88282667,  0.11717333],\n",
       "       [ 0.592476  ,  0.407524  ],\n",
       "       [ 0.85016058,  0.14983942],\n",
       "       [ 0.90342197,  0.09657803],\n",
       "       [ 0.05120533,  0.94879467]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9./10. Evaluate the *Test* set (did so above and through Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76223776,  0.83216783,  0.76223776,  0.76056338,  0.82269504])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Check the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.90      0.85       104\n",
      "          1       0.84      0.69      0.76        74\n",
      "\n",
      "avg / total       0.82      0.81      0.81       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, logreg_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What do the classification metrics tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification metrics give us a variety of information regarding the ability of our models to accurately predict whether or not a given passenged on the Titanic died.  The precision is calculated by measuring the the True Positives(TP)/all predictived positives (TP + False Positives(FP)).  Practically speaking, this is an indicator of our model's ability to minimize False Positives.  \n",
    "\n",
    "The Recall Value measures our ability to minimize False Negatives and is calculated much the same way as precision (TN/TN+FN).  \n",
    "\n",
    "The F1 score is a statistic that uses both the precision and recall to make a weighted score for how our model performs (respective to the classication categories).  \n",
    "\n",
    "Using these scores I am able to say that my model is overly optimistic(or pessimistic in this case, womp...) in predicting that a passenger on the Titanic died and could be improved by prediciting more passenger survival.  Conversely, my model has a very strong recall score in regards to predicting if a passenger died.  This intuitively makes sens as more people died on the Titanic than survived.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Check the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 10]\n",
      " [23 51]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(y_test, logreg_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. What does the Confusion Matrix tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix gives the number of false negatives, false positives, true negatives, and true positives when running the model on a test set of data.  These scores are used to calculate the recall, precision, and f1 values above.  My model in this case accurately predicted (on the test set) that 94 people died and 51 survived, while incorrectly predicting that 10 people survived and 23 did not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119028450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proba = lr.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label= 'ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve of LogReg Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. What does the ROC curve tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC Curve is a visualization of the accuracy of a given model which is exhibited through plotting the FPR vs. the TPR.  a perfect model would hug the y-axis until it reached top of the constraints, and would then hug the top of the constraint across the x-axis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use GridSearchCV with logistic regression to search for optimal parameters \n",
    "\n",
    "- Use the provided parameter grid. Feel free to add if you like (such as n_jobs).\n",
    "- Use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,1,50),\n",
    "    'solver':['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.32571e-05,   1.75751e-05,   2.32995e-05,\n",
       "         3.08884e-05,   4.09492e-05,   5.42868e-05,   7.19686e-05,\n",
       "         9.54095e-05,   1.26486e-04,   1.67683e-04,   2.22300e-04,\n",
       "         2.94705e-04,   3.90694e-04,   5.17947e-04,   6.8...6e+00,   4.29193e+00,   5.68987e+00,\n",
       "         7.54312e+00,   1.00000e+01]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "gridsearch = GridSearchCV(classifier, logreg_parameters, cv=5)\n",
    "gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the best parameters and best score. Are they better than the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 0.035564803062231289, 'solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7893258426966292"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print gridsearch.best_params_\n",
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain the difference between the difference between the L1 (Lasso) and L2 (Ridge) penalties on the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 (Lasso) coefficent regularization uses a coefficient penalty that is the absolute values of the coefficients & allows the coefficents to move towards a 0 value.  This is useful for helping to eliminate Type 1 errors aka false positives.  \n",
    "\n",
    "L2(Ridge) uses a the sume of the squares of the coefficients as a penalty, and does not allow the coefficients to move towards zero.  This helps negate type 2 errors aka false negatives.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What hypothetical situations are the Ridge and Lasso penalties useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso is useful to help models which have a high number of outliers in the predictive variables.  As above, Lasso regression is useful to eliminate type 1 errors, while Ride is useful for eliminating type 2 errors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Gridsearch and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform Gridsearch for the same classification problem as above, but use KNeighborsClassifier as your estimator\n",
    "\n",
    "At least have number of neighbors and weights in your parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvals = range(1,51)\n",
    "neigh_parameters = {'n_neighbors':kvals, 'weights':['uniform','distance']}\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "neighbors_gridsearch = GridSearchCV(neigh, neigh_parameters, cv=5)\n",
    "neighbors_gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the best parameters and score for the gridsearched kNN model. How does it compare to the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709269662921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 22, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print neighbors_gridsearch.best_score_\n",
    "neighbors_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How does the number of neighbors affect the bias-variance tradeoff of your model? [BONUS] Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A KNN Classification model with n_neighbors = 1 is a model with very high variance.  This is because the model's decision making parameters would need to be very irregular to accomodate a high degree of variability when making predictions.  As n_neighbors increases, the predictive value of a single point decreases and allows for a smoother decision boundry and a decrease in the variance of your model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In what hypothetical scenario(s) might you prefer logistic regression over kNN, aside from model performance metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "KNN is useful when your model skews towards primarily classification (compared to linear) variables.  Logistic regression is better when the predictive variables are primarily linear values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a new kNN model with the optimal parameters found in gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=22, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh2 = KNeighborsClassifier(n_neighbors=22, weights='uniform')\n",
    "neigh2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Construct the confusion matrix for the optimal kNN model. Is it different from the logistic regression model? If so, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674157303371\n",
      "[[85 19]\n",
      " [39 35]]\n"
     ]
    }
   ],
   "source": [
    "neigh2.fit(X_train, y_train)\n",
    "knn_preds = neigh2.predict(X_test)\n",
    "matrix = confusion_matrix(y_test, knn_preds)\n",
    "print neigh2.score(X_test, y_test)\n",
    "print matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix for the optimized KNN model performs more poorly than my original model.  This is most likely due to the fact that the most important predictive variable (fare) was the best predictor, and was not used as efficiently in the KNN model.  The matrix shows an increase in both false negatives and false positives.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
